{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9896678-5e8a-4b64-abc3-2efc332322ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65f75a8-97c9-476a-aeb5-6d276cf61e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the path\n",
    "cwd = os.getcwd()\n",
    "file_path = os.path.join(cwd, 'data/train_author_nlp.csv')\n",
    "\n",
    "#read the file\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2422da-2ed6-45bb-8d00-9d2c1b730196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the df by author\n",
    "by_author = df.groupby('author')\n",
    "\n",
    "# Initialize ConditionalFreqDist to store word frequency by author\n",
    "word_freq_by_author = nltk.probability.ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3169d5ee-4d91-4250-909c-8906c6def59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each author group\n",
    "for name, group in by_author:\n",
    "    sentences = group['text'].str.cat(sep=' ')\n",
    "    sentences = sentences.lower()\n",
    "    tokens = word_tokenize(sentences)\n",
    "    frequency = nltk.FreqDist(tokens)\n",
    "    word_freq_by_author[name] = frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e94a760-0289-4056-ad1e-eaaf286fe4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: EAP\n",
      "Frequency of blood: 0.0001465037315362209\n",
      "\n",
      "Author: HPL\n",
      "Frequency of blood: 0.00022994981345321385\n",
      "\n",
      "Author: MWS\n",
      "Frequency of blood: 0.00022772649518331984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the frequency of the word 'blood' for each author\n",
    "\n",
    "word = 'blood'\n",
    "\n",
    "for author in word_freq_by_author.keys():\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Frequency of {word}: {word_freq_by_author[author].freq(word)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70284da7-63fd-4ea6-a7e7-8176ce195373",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"It was a dark and stormy night.\"\n",
    "preprocessed_test_sentence = nltk.tokenize.word_tokenize(test_sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74124917-92f9-442f-b46b-73f40ad40e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAP: 1.3332398139489038e-21\n",
      "HPL: 2.473639795463954e-20\n",
      "MWS: 1.747881957447149e-21\n",
      "\n",
      "Most Likely Author: HPL\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store author probabilities\n",
    "test_probabilities = pd.DataFrame(columns=['author', 'joint_probability'])\n",
    "\n",
    "# Iterate over each author\n",
    "for author in word_freq_by_author.keys():\n",
    "    joint_probability = 1.0\n",
    "    \n",
    "    # Calculate the joint probability for each word in the pre-processed test sentence\n",
    "    for word in preprocessed_test_sentence:\n",
    "        word_freq = word_freq_by_author[author].freq(word)\n",
    "        smoothed_word_freq = word_freq + 0.000001\n",
    "        joint_probability *= smoothed_word_freq\n",
    "    \n",
    "    # Create a DataFrame row with the author and its joint probability\n",
    "    output = pd.DataFrame([[author, joint_probability]], columns=['author', 'joint_probability'])\n",
    "    test_probabilities = pd.concat([test_probabilities, output], ignore_index=True)\n",
    "\n",
    "# Find the author with the highest joint probability\n",
    "most_likely_author = test_probabilities.loc[test_probabilities['joint_probability'].idxmax(), 'author']\n",
    "\n",
    "# Print the joint probabilities for each author\n",
    "for _, row in test_probabilities.iterrows():\n",
    "    print(f\"{row['author']}: {row['joint_probability']}\")\n",
    "    \n",
    "# Print the most likely author\n",
    "print(f\"\\nMost Likely Author: {most_likely_author}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
